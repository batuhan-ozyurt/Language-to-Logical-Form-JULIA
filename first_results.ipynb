{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Pkg; Pkg.add(\"Distributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please enter here the paths of the training file and the test file\n",
    "training_file = \n",
    "test_file = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet: Knet, AutoGrad, param, param0, mat, RNN, relu, Data, adam, progress, nll, zeroone\n",
    "using Distributions\n",
    "import .Iterators: cycle, Cycle, take\n",
    "using IterTools\n",
    "import CUDA\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function tok_int(training_file)\n",
    "    \n",
    "    #global int2tok_input, int2tok_output\n",
    "    f = open(training_file)\n",
    "    tok2int_input = Dict{String,Int}() #keys: unique input tokens. values: id number of the token.\n",
    "    int2tok_input = Vector{String}() #indices: numbers. values: tokens corresponding to those numbers.\n",
    "    push!(int2tok_input, \"<s>\") #start token\n",
    "    push!(int2tok_input, \"</s>\") #stop token\n",
    "    tok2int_input[\"<s>\"] = 1\n",
    "    tok2int_input[\"</s>\"] = 2\n",
    "    tok2int_output = Dict{String,Int}() #keys: unique output tokens. values: id number of the token.\n",
    "    int2tok_output = Vector{String}() #keys: numbers. values: tokens corresponding to those numbers.\n",
    "    push!(int2tok_output, \"<s>\") #start token\n",
    "    push!(int2tok_output, \"</s>\") #stop token\n",
    "    tok2int_output[\"<s>\"] = 1\n",
    "    tok2int_output[\"</s>\"] = 2\n",
    "    while ! eof(f)\n",
    "        seq = readline(f)\n",
    "        seq = chomp(seq)\n",
    "        input, output = split(seq, \"\\t\")\n",
    "        tokens = split(input, \" \")\n",
    "        for token in tokens\n",
    "            if !haskey(tok2int_input, token)\n",
    "                push!(int2tok_input, token)\n",
    "                tok2int_input[token] = length(int2tok_input)\n",
    "            end            \n",
    "        end\n",
    "        tokens = split(output, \" \")\n",
    "        for token in tokens\n",
    "            if !haskey(tok2int_output, token)\n",
    "                push!(int2tok_output, token)\n",
    "                tok2int_output[token] = length(int2tok_output)\n",
    "            end           \n",
    "        end        \n",
    "    end\n",
    "    push!(int2tok_input, \"UNK\") \n",
    "    tok2int_input[\"UNK\"] = 123\n",
    "    push!(int2tok_output, \"UNK\") \n",
    "    tok2int_output[\"UNK\"] = 123\n",
    "    Vq = length(int2tok_input) #number of unique input tokens\n",
    "    Va = length(int2tok_output) #number of unique output tokens    \n",
    "    return int2tok_input, tok2int_input, int2tok_output, tok2int_output, Va, Vq\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function data_reader(training_file, tok2int_input, tok2int_output)\n",
    "    \n",
    "    data = []\n",
    "    f = open(training_file)\n",
    "    while ! eof(f)\n",
    "        seq = readline(f)\n",
    "        seq = chomp(seq)\n",
    "        input, output = split(seq, \"\\t\")\n",
    "        tokens = split(input, \" \")\n",
    "        s = Vector{Int}() #vector that stores the token ids.\n",
    "        global n_in = 0 #just to check the number of unknown tokens\n",
    "        for token in tokens            \n",
    "            if haskey(tok2int_input, token)\n",
    "                push!(s, tok2int_input[token])\n",
    "            else\n",
    "                push!(s, tok2int_input[\"UNK\"])\n",
    "                n_in += 1\n",
    "            end \n",
    "        end        \n",
    "\n",
    "        tokens = split(output, \" \")\n",
    "        s2 = Vector{Int}() #vector that stores the token ids.\n",
    "        global n_out = 0 #just to check the number of unknown tokens\n",
    "        for token in tokens\n",
    "            if haskey(tok2int_output, token)\n",
    "                push!(s2, tok2int_output[token])\n",
    "            else\n",
    "                push!(s2, tok2int_output[\"UNK\"])\n",
    "                n_out += 1\n",
    "            end\n",
    "        end \n",
    "        push!(data, (s, s2))\n",
    "    end    \n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minibatch(data,batchsize)\n",
    "    n = length(data)\n",
    "    batch_data = Any[]\n",
    "    p = 0\n",
    "    while p + batchsize <= n\n",
    "        max_seq_len = length(data[p+batchsize][1])\n",
    "        enc_seq = zeros(Int64, batchsize, max_seq_len+2) \n",
    "        enc_seq[:,1] .= 1\n",
    "        for i in 1:batchsize\n",
    "            seq = data[p+i][1]\n",
    "            seq_len = length(seq)\n",
    "            for j in 1:seq_len\n",
    "                enc_seq[i,j+1] = seq[seq_len-j+1]\n",
    "            end\n",
    "            for k in seq_len+2:max_seq_len+2 \n",
    "                enc_seq[i,k] = 2\n",
    "            end\n",
    "        end\n",
    "        max_seq_len = -1\n",
    "        for i in 1:batchsize\n",
    "            seq = data[p+i][2]\n",
    "            if length(seq) > max_seq_len \n",
    "                max_seq_len = length(seq)\n",
    "            end\n",
    "        end\n",
    "        dec_seq = zeros(Int64, batchsize, max_seq_len+2)\n",
    "        dec_seq[:,1] .= 1\n",
    "        for i in 1:batchsize\n",
    "            seq = data[p+i][2]\n",
    "            seq_len = length(seq)\n",
    "            for j in 1:seq_len\n",
    "                dec_seq[i,j + 1] = seq[j]\n",
    "            end\n",
    "            dec_seq[i,(seq_len + 2):end] .= 2\n",
    "        end\n",
    "        p += batchsize\n",
    "        push!(batch_data, (enc_seq, dec_seq))\n",
    "    end\n",
    "    return batch_data\n",
    "end               \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mask(a, pad)\n",
    "    a = copy(a)\n",
    "    for i in 1:size(a, 1)\n",
    "        j = size(a,2)\n",
    "        while a[i, j] == pad && j > 1\n",
    "            if a[i, j - 1] == pad\n",
    "                a[i, j] = 0\n",
    "            end\n",
    "            j -= 1\n",
    "        end\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Embed\n",
    "    w\n",
    "end\n",
    "function Embed(embedsize::Int, vocabsize::Int)\n",
    "    w = rand(Uniform(-0.08,0.08),embedsize,vocabsize)\n",
    "    w = Knet.Param(convert(Knet.KnetArray{Float32},w))\n",
    "    return Embed(w)\n",
    "end\n",
    "(e::Embed)(x) = e.w[:,x] #x: word id\n",
    "\n",
    "struct Linear\n",
    "    w\n",
    "    b\n",
    "    f\n",
    "end\n",
    "Linear(i::Int,o::Int,f=identity) = Linear(param(o,i), param0(o), f)\n",
    "(d::Linear)(x) = d.f.(d.w * mat(x,dims=1) .+ d.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct seq2seq\n",
    "    input_embed\n",
    "    output_embed\n",
    "    encoder\n",
    "    decoder\n",
    "    linear\n",
    "    dropout\n",
    "end\n",
    "\n",
    "function seq2seq(X::Int, H::Int, Vq::Int, Va::Int, dropout::Real)\n",
    "    a = Embed(X, Vq)\n",
    "    b = Embed(X, Va)\n",
    "    c = RNN(X, H; rnnType=:lstm, numLayers=1, dropout=dropout)\n",
    "    d = RNN(X, H; rnnType=:lstm, numLayers=1, dropout=dropout)\n",
    "    e = Linear(H,Va)\n",
    "    f = dropout\n",
    "    return seq2seq(a, b, c, d, e, f)\n",
    "end\n",
    "\n",
    "function (s::seq2seq)(x, y; average=true) \n",
    "    \n",
    "    s.encoder.h, s.encoder.c = 0, 0\n",
    "    x_embedded = s.input_embed(x)\n",
    "    y_embedded = s.output_embed(y)\n",
    "    encoder_out = s.encoder(x_embedded) \n",
    "    s.decoder.h, s.decoder.c = s.encoder.h, s.encoder.c\n",
    "    decoder_out = s.decoder(y_embedded[:, :, 1:end-1])\n",
    "    dims = size(decoder_out)\n",
    "    output = s.linear(Knet.dropout(reshape(decoder_out, dims[1], dims[2] * dims[3]), s.dropout))\n",
    "    scores = reshape(output, size(output, 1), dims[2], dims[3])\n",
    "    nll(scores, mask(y[:, 2:end], 2); dims=1, average=average)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR PREDICTION/TESTING\n",
    "function (s::seq2seq)(x; stopfactor = 4)\n",
    "    s.encoder.h, s.encoder.c = 0, 0\n",
    "    x_embedded = s.input_embed(x)\n",
    "    s.encoder(x_embedded)\n",
    "    s.decoder.h, s.decoder.c = s.encoder.h, s.encoder.c\n",
    "    step = fill(1, size(x)[1], 1)\n",
    "    out = fill(2, size(x)[1], 0)\n",
    "    stopping_criteria = fill(false, size(x)[1])\n",
    "    for i in 1:(stopfactor * size(x,2))\n",
    "        if sum(stopping_criteria) == size(x)[1]\n",
    "            break\n",
    "        end\n",
    "        stepembed = s.output_embed(step)\n",
    "        decoder_out = s.decoder(stepembed)\n",
    "        dims = size(decoder_out)\n",
    "        output = s.linear(reshape(decoder_out, dims[1], dims[2] * dims[3]))\n",
    "        step = transpose([i[1] for i in argmax(output; dims=1)])\n",
    "        out = hcat(out, step)\n",
    "        for e in findall(x -> x == 2, step)\n",
    "            stopping_criteria[e[1]] = true\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function model_accuracy(model, data)\n",
    "    total = 0\n",
    "    no_sequences = 0\n",
    "    for (x, y) in data\n",
    "        y_pred = model(x)\n",
    "        for i in 1:size(x, 1)\n",
    "            no_sequences += 1            \n",
    "            y_clipped = []\n",
    "            y_pred_clipped = []\n",
    "            for j in 1:size(y,2)                \n",
    "                if y[i,j] == 2                   \n",
    "                    append!(y_clipped, y[i,2:j])\n",
    "                    break\n",
    "                end\n",
    "            end            \n",
    "            for j in 1:size(y_pred,2)\n",
    "                if y_pred[i,j] == 2 \n",
    "                    append!(y_pred_clipped, y_pred[i,1:j])\n",
    "                    break\n",
    "                end\n",
    "            end\n",
    "            if length(y_clipped) == length(y_pred_clipped)\n",
    "                if sum(y_pred_clipped .== y_clipped) == size(y_clipped,1)                   \n",
    "                    total += 1                    \n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return total / no_sequences    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "int2tok_input, tok2int_input, int2tok_output, tok2int_output, Va, Vq = tok_int(training_file)\n",
    "trndata = data_reader(training_file, tok2int_input, tok2int_output)\n",
    "tstdata = data_reader(test_file, tok2int_input, tok2int_output)\n",
    "X = 200\n",
    "H = 150 # H=150 for GEO and JOBS datasets, H=200 for ATIS dataset.\n",
    "trndata_batch = minibatch(trndata, 20)\n",
    "tstdata_batch = minibatch(tstdata, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_model = seq2seq(X,H,Vq,Va,0.5) # dropout=0.5 for GEO and JOBS datasets, dropout = 0.3 for ATIS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in 1:200\n",
    "    Knet.rmsprop!(my_model, trndata_batch;rho=0.95,gclip=5)\n",
    "    if i%5 == 0\n",
    "        println(\"After $i epochs\")\n",
    "        println(\"train accuracy: \", model_accuracy(my_model, trndata_batch))\n",
    "        println(\"test accuracy: \", model_accuracy(my_model, tstdata_batch))\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
