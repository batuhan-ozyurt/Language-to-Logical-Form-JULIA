{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Untitled Folder/Datasets/seq2tree_atis/test.txt\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Please enter here the paths of the training file and the test file\n",
    "training_file = \"Untitled Folder/Datasets/seq2tree_atis/train.txt\"\n",
    "test_file = \"Untitled Folder/Datasets/seq2tree_atis/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Untitled Folder/Datasets/seq2tree_geoqueries/test.txt\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Please enter here the paths of the training file and the test file\n",
    "training_file = \"Untitled Folder/Datasets/seq2tree_geoqueries/train.txt\"\n",
    "test_file = \"Untitled Folder/Datasets/seq2tree_geoqueries/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Untitled Folder/Datasets/seq2tree_jobqueries/test.txt\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file = \"Untitled Folder/Datasets/seq2tree_jobqueries/train.txt\"\n",
    "test_file = \"Untitled Folder/Datasets/seq2tree_jobqueries/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet: Knet, AutoGrad, param, param0, mat, RNN, relu, Data, adam, progress, nll, zeroone\n",
    "using Distributions\n",
    "import .Iterators: cycle, Cycle, take\n",
    "using IterTools\n",
    "import CUDA\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tok_int (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function tok_int(training_file)\n",
    "    \n",
    "    #global int2tok_input, int2tok_output\n",
    "    f = open(training_file)\n",
    "    \n",
    "    tok2int_input = Dict{String,Int}() #keys: unique input tokens. values: id number of the token.\n",
    "    int2tok_input = Vector{String}() #indices: numbers. values: tokens corresponding to those numbers.\n",
    "    push!(int2tok_input, \"<s>\") #start token\n",
    "    push!(int2tok_input, \"</s>\") #stop token\n",
    "    tok2int_input[\"<s>\"] = 1\n",
    "    tok2int_input[\"</s>\"] = 2\n",
    "    \n",
    "    tok2int_output = Dict{String,Int}() #keys: unique output tokens. values: id number of the token.\n",
    "    int2tok_output = Vector{String}() #keys: numbers. values: tokens corresponding to those numbers.\n",
    "    push!(int2tok_output, \"<s>\") #start token\n",
    "    push!(int2tok_output, \"</s>\") #stop token\n",
    "    tok2int_output[\"<s>\"] = 1\n",
    "    tok2int_output[\"</s>\"] = 2\n",
    "    \n",
    "    while ! eof(f)\n",
    "        \n",
    "        seq = readline(f)\n",
    "        seq = chomp(seq)\n",
    "        input, output = split(seq, \"\\t\")\n",
    "        tokens = split(input, \" \")\n",
    "        \n",
    "        for token in tokens\n",
    "            if !haskey(tok2int_input, token)\n",
    "                push!(int2tok_input, token)\n",
    "                tok2int_input[token] = length(int2tok_input)\n",
    "            end            \n",
    "        end\n",
    "        \n",
    "        tokens = split(output, \" \")\n",
    "        \n",
    "        for token in tokens\n",
    "            if !haskey(tok2int_output, token)\n",
    "                push!(int2tok_output, token)\n",
    "                tok2int_output[token] = length(int2tok_output)\n",
    "            end           \n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    push!(int2tok_input, \"UNK\") \n",
    "    tok2int_input[\"UNK\"] = length(int2tok_input)\n",
    "    push!(int2tok_output, \"UNK\") \n",
    "    tok2int_output[\"UNK\"] = length(int2tok_output)\n",
    "    \n",
    "    @assert length(int2tok_input) == length(tok2int_input)\n",
    "    @assert length(int2tok_output) == length(tok2int_output)\n",
    "    \n",
    "    Vq = length(int2tok_input) #number of unique input tokens\n",
    "    Va = length(int2tok_output) #number of unique output tokens \n",
    "    \n",
    "    return int2tok_input, tok2int_input, int2tok_output, tok2int_output, Va, Vq\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_reader (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function data_reader(training_file, tok2int_input, tok2int_output)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    f = open(training_file)\n",
    "    \n",
    "    while ! eof(f)\n",
    "        \n",
    "        seq = readline(f)\n",
    "        seq = chomp(seq)\n",
    "        input, output = split(seq, \"\\t\")\n",
    "        tokens = split(input, \" \")\n",
    "        \n",
    "        src_tokens = Vector{Int}() #vector that stores the token ids.\n",
    "        global n_in = 0 #just to check the number of unknown tokens\n",
    "        \n",
    "        for token in tokens\n",
    "            \n",
    "            if haskey(tok2int_input, token)\n",
    "                push!(src_tokens, tok2int_input[token])\n",
    "            else\n",
    "                push!(src_tokens, tok2int_input[\"UNK\"])\n",
    "                n_in += 1\n",
    "            end\n",
    "            \n",
    "        end        \n",
    "\n",
    "        tokens = split(output, \" \")\n",
    "        tgt_tokens = Vector{Int}() #vector that stores the token ids.\n",
    "        global n_out = 0 #just to check the number of unknown tokens\n",
    "        \n",
    "        for token in tokens\n",
    "            \n",
    "            if haskey(tok2int_output, token)\n",
    "                push!(tgt_tokens, tok2int_output[token])\n",
    "            else\n",
    "                push!(tgt_tokens, tok2int_output[\"UNK\"])\n",
    "                n_out += 1\n",
    "            end\n",
    "            \n",
    "        end \n",
    "        \n",
    "        push!(data, (src_tokens, tgt_tokens))\n",
    "        \n",
    "    end    \n",
    "    \n",
    "    return data\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minibatch (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ATIS: source sequence lengths are monotonically increasing as you read through the lines of the trn file.\n",
    "# Not the same for the target sequences!\n",
    "\n",
    "function minibatch(data, batchsize)\n",
    "    \n",
    "    n = length(data)\n",
    "    batch_data = Any[]\n",
    "    p = 0\n",
    "    \n",
    "    while p + batchsize <= n\n",
    "        \n",
    "        max_seq_len = length(data[p+batchsize][1])\n",
    "        enc_seq = zeros(Int64, batchsize, max_seq_len+2) \n",
    "        enc_seq[:,max_seq_len+2] .= 2 #end of sequence token\n",
    "        \n",
    "        for i in 1:batchsize\n",
    "            \n",
    "            seq = data[p+i][1]\n",
    "            seq_len = length(seq)\n",
    "            \n",
    "            for j in 1:seq_len\n",
    "                enc_seq[i, max_seq_len-seq_len+j+1] = seq[seq_len-j+1]\n",
    "            end\n",
    "            \n",
    "            for k in 1:(max_seq_len+1-seq_len) #pad the start with start of seq tokens\n",
    "                enc_seq[i, k] = 1\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        max_seq_len = -1\n",
    "        \n",
    "        for i in 1:batchsize\n",
    "            \n",
    "            seq = data[p+i][2]\n",
    "            \n",
    "            if length(seq) > max_seq_len \n",
    "                max_seq_len = length(seq)\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        dec_seq = zeros(Int64, batchsize, max_seq_len+2)\n",
    "        dec_seq[:,1] .= 1\n",
    "        \n",
    "        for i in 1:batchsize\n",
    "            \n",
    "            seq = data[p+i][2]\n",
    "            seq_len = length(seq)\n",
    "            \n",
    "            for j in 1:seq_len\n",
    "                dec_seq[i, (j+1)] = seq[j]\n",
    "            end\n",
    "            \n",
    "            dec_seq[i, (seq_len+2):end] .= 2\n",
    "            \n",
    "        end\n",
    "        \n",
    "        p += batchsize\n",
    "        \n",
    "        push!(batch_data, (enc_seq, dec_seq))\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return batch_data\n",
    "    \n",
    "end               \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mask (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mask(a, pad)\n",
    "    \n",
    "    a = copy(a)\n",
    "    \n",
    "    for i in 1:size(a, 1)\n",
    "        \n",
    "        j = size(a,2)\n",
    "        \n",
    "        while a[i, j] == pad && j > 1\n",
    "            \n",
    "            if a[i, j - 1] == pad\n",
    "                a[i, j] = 0\n",
    "            end\n",
    "            \n",
    "            j -= 1\n",
    "            \n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return a\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Embed    \n",
    "    w\n",
    "end\n",
    "\n",
    "function Embed(embedsize::Int, vocabsize::Int)\n",
    "    \n",
    "    w = rand(Uniform(-0.08,0.08), embedsize, vocabsize)\n",
    "    w = Knet.Param(convert(Knet.KnetArray{Float32},w))\n",
    "    \n",
    "    return Embed(w)\n",
    "    \n",
    "end\n",
    "\n",
    "(e::Embed)(x) = e.w[:,x] #x: word id\n",
    "\n",
    "struct Linear\n",
    "    w\n",
    "    b\n",
    "    f\n",
    "end\n",
    "\n",
    "Linear(i::Int,o::Int,f=identity) = Linear(param(o,i), param0(o), f)\n",
    "\n",
    "(d::Linear)(x) = d.f.(d.w * mat(x,dims=1) .+ d.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct seq2seq\n",
    "    input_embed\n",
    "    output_embed\n",
    "    encoder\n",
    "    decoder\n",
    "    linear\n",
    "    dropout\n",
    "end\n",
    "\n",
    "function seq2seq(X::Int, H::Int, Vq::Int, Va::Int, dropout::Real)\n",
    "    \n",
    "    a = Embed(X, Vq)\n",
    "    b = Embed(X, Va)\n",
    "    c = RNN(X, H; rnnType=:lstm, numLayers=1, dropout=dropout)\n",
    "    d = RNN(X, H; rnnType=:lstm, numLayers=1, dropout=dropout)\n",
    "    e = Linear(H,Va)\n",
    "    f = dropout\n",
    "    \n",
    "    return seq2seq(a, b, c, d, e, f)\n",
    "    \n",
    "end\n",
    "\n",
    "function (s::seq2seq)(x, y; average=true) \n",
    "    \n",
    "    s.encoder.h = 0\n",
    "    s.encoder.c = 0\n",
    "    \n",
    "    x_embedded = s.input_embed(x) # BURAYA DROPUT EKLE!\n",
    "    y_embedded = s.output_embed(y) # BURAYA DROPUT EKLE!\n",
    "    \n",
    "    encoder_out = s.encoder(x_embedded)\n",
    "    \n",
    "    s.decoder.h = s.encoder.h\n",
    "    s.decoder.c = s.encoder.c\n",
    "    \n",
    "    decoder_out = s.decoder(y_embedded[:, :, 1:end-1])\n",
    "    \n",
    "    dims = size(decoder_out)\n",
    "    \n",
    "    output = s.linear(Knet.dropout(reshape(decoder_out, dims[1], dims[2] * dims[3]), s.dropout))\n",
    "    \n",
    "    scores = reshape(output, size(output, 1), dims[2], dims[3])\n",
    "    \n",
    "    nll(scores, mask(y[:, 2:end], 2); dims=1, average=average)\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR PREDICTION/TESTING\n",
    "\n",
    "function (s::seq2seq)(x; stopfactor = 4)\n",
    "    \n",
    "    s.encoder.h = 0\n",
    "    s.encoder.c = 0\n",
    "    \n",
    "    x_embedded = s.input_embed(x)\n",
    "    \n",
    "    encoder_out = s.encoder(x_embedded)\n",
    "    \n",
    "    s.decoder.h = s.encoder.h\n",
    "    s.decoder.c = s.encoder.c\n",
    "    \n",
    "    step = fill(1, size(x)[1], 1)\n",
    "    out = fill(2, size(x)[1], 0)\n",
    "    stopping_criteria = fill(false, size(x)[1])\n",
    "    \n",
    "    for i in 1:(stopfactor * size(x,2))\n",
    "        \n",
    "        if sum(stopping_criteria) == size(x)[1]\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        step_embed = s.output_embed(step)\n",
    "        \n",
    "        decoder_out = s.decoder(step_embed)\n",
    "        \n",
    "        dims = size(decoder_out)\n",
    "        \n",
    "        output = s.linear(reshape(decoder_out, dims[1], dims[2] * dims[3]))\n",
    "        \n",
    "        step = transpose([i[1] for i in argmax(output; dims=1)])\n",
    "        \n",
    "        out = hcat(out, step)\n",
    "        \n",
    "        for e in findall(x -> x == 2, step)\n",
    "            stopping_criteria[e[1]] = true\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return out\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function model_accuracy(model, data)\n",
    "    \n",
    "    total = 0\n",
    "    no_sequences = 0\n",
    "    \n",
    "    for (x, y) in data\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        for i in 1:size(x, 1)\n",
    "            \n",
    "            no_sequences += 1            \n",
    "            y_clipped = []\n",
    "            y_pred_clipped = []\n",
    "            \n",
    "            for j in 1:size(y,2)   \n",
    "                \n",
    "                if y[i,j] == 2                   \n",
    "                    append!(y_clipped, y[i,2:j])\n",
    "                    break\n",
    "                end\n",
    "                \n",
    "            end\n",
    "            \n",
    "            for j in 1:size(y_pred,2)\n",
    "                \n",
    "                if y_pred[i,j] == 2 \n",
    "                    append!(y_pred_clipped, y_pred[i,1:j])\n",
    "                    break\n",
    "                end     \n",
    "               \n",
    "            end\n",
    "            \n",
    "            if length(y_clipped) == length(y_pred_clipped)\n",
    "                \n",
    "                if sum(y_pred_clipped .== y_clipped) == size(y_clipped, 1)                   \n",
    "                    total += 1                    \n",
    "                end\n",
    "                \n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return total / no_sequences\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22-element Array{Any,1}:\n",
       " ([1 1 … 69 2; 1 1 … 69 2; … ; 1 6 … 7 2; 1 157 … 6 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 8 2])\n",
       " ([1 157 … 6 2; 1 157 … 23 2; … ; 1 6 … 69 2; 1 76 … 14 2], [1 3 … 8 2; 1 3 … 8 2; … ; 1 3 … 2 2; 1 56 … 2 2])\n",
       " ([1 1 … 14 2; 1 1 … 14 2; … ; 1 145 … 6 2; 1 145 … 23 2], [1 56 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 1 … 6 2; 1 1 … 23 2; … ; 1 23 … 159 2; 1 23 … 69 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 42 … 14 2; 1 51 … 14 2; … ; 1 23 … 69 2; 1 23 … 69 2], [1 36 … 2 2; 1 15 … 2 2; … ; 1 3 … 8 2; 1 3 … 8 2])\n",
       " ([1 6 … 69 2; 1 23 … 69 2; … ; 1 75 … 81 2; 1 75 … 81 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 56 … 2 2; 1 56 … 2 2])\n",
       " ([1 1 … 69 2; 1 1 … 69 2; … ; 1 32 … 14 2; 1 70 … 69 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 1 … 14 2; 1 1 … 18 2; … ; 1 43 … 69 2; 1 6 … 69 2], [1 56 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 23 … 43 2; 1 23 … 14 2; … ; 1 34 … 69 2; 1 34 … 69 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 34 … 69 2; 1 34 … 69 2; … ; 1 76 … 14 2; 1 76 … 14 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 86 … 2 2; 1 86 … 2 2])\n",
       " ([1 76 … 14 2; 1 76 … 113 2; … ; 1 23 … 184 2; 1 34 … 210 2], [1 86 … 2 2; 1 86 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 1 … 210 2; 1 1 … 210 2; … ; 1 6 … 139 2; 1 23 … 139 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 132 … 57 2; 1 5 … 18 2; … ; 1 23 … 139 2; 1 23 … 139 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 23 … 113 2; 1 6 … 43 2; … ; 1 23 … 18 2; 1 6 … 210 2], [1 3 … 8 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 112 … 14 2; 1 34 … 139 2; … ; 1 6 … 14 2; 1 6 … 14 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 67 … 2 2; 1 68 … 2 2])\n",
       " ([1 6 … 14 2; 1 23 … 14 2; … ; 1 258 … 81 2; 1 9 … 184 2], [1 68 … 2 2; 1 68 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 1 … 210 2; 1 145 … 139 2; … ; 1 61 … 101 2; 1 237 … 103 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 67 … 8 2; 1 3 … 2 2])\n",
       " ([1 1 … 81 2; 1 1 … 18 2; … ; 1 99 … 139 2; 1 99 … 14 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 1 … 97 2; 1 1 … 97 2; … ; 1 34 … 139 2; 1 99 … 139 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 8 2; 1 3 … 2 2])\n",
       " ([1 1 … 139 2; 1 1 … 43 2; … ; 1 61 … 97 2; 1 247 … 139 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 68 … 2 2; 1 3 … 2 2])\n",
       " ([1 1 … 18 2; 1 1 … 97 2; … ; 1 23 … 97 2; 1 49 … 97 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 1 … 18 2; 1 1 … 69 2; … ; 1 99 … 184 2; 1 23 … 15 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 8 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2tok_input, tok2int_input, int2tok_output, tok2int_output, Va, Vq = tok_int(training_file)\n",
    "\n",
    "trndata = data_reader(training_file, tok2int_input, tok2int_output)\n",
    "tstdata = data_reader(test_file, tok2int_input, tok2int_output)\n",
    "\n",
    "X = 200\n",
    "H = 200\n",
    "\n",
    "trndata_batch = minibatch(trndata, 20)\n",
    "tstdata_batch = minibatch(tstdata, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seq2seq(Embed(P(Knet.KnetArrays.KnetArray{Float32,2}(200,436))), Embed(P(Knet.KnetArrays.KnetArray{Float32,2}(200,169))), LSTM(input=200,hidden=200,dropout=0.3), LSTM(input=200,hidden=200,dropout=0.3), Linear(P(Knet.KnetArrays.KnetArray{Float32,2}(169,200)), P(Knet.KnetArrays.KnetArray{Float32,1}(169)), identity), 0.3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = seq2seq(X,H,Vq,Va,0.3) # dropout=0.4 for GEO and JOBS datasets, dropout = 0.3 for ATIS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 epochs\n",
      "test accuracy: 0.045454545454545456\n",
      "After 10 epochs\n",
      "test accuracy: 0.1159090909090909\n",
      "After 15 epochs\n",
      "test accuracy: 0.15227272727272728\n",
      "After 20 epochs\n",
      "test accuracy: 0.6022727272727273\n",
      "After 25 epochs\n",
      "test accuracy: 0.6954545454545454\n",
      "After 30 epochs\n",
      "test accuracy: 0.7204545454545455\n",
      "After 35 epochs\n",
      "test accuracy: 0.7204545454545455\n",
      "After 40 epochs\n",
      "test accuracy: 0.7477272727272727\n",
      "After 45 epochs\n",
      "test accuracy: 0.7772727272727272\n",
      "After 50 epochs\n",
      "test accuracy: 0.775\n",
      "After 55 epochs\n",
      "test accuracy: 0.7727272727272727\n",
      "After 60 epochs\n",
      "test accuracy: 0.7931818181818182\n",
      "After 65 epochs\n",
      "test accuracy: 0.8022727272727272\n",
      "After 70 epochs\n",
      "test accuracy: 0.7909090909090909\n",
      "After 75 epochs\n",
      "test accuracy: 0.7977272727272727\n",
      "After 80 epochs\n",
      "test accuracy: 0.7977272727272727\n",
      "After 85 epochs\n",
      "test accuracy: 0.8204545454545454\n",
      "After 90 epochs\n",
      "test accuracy: 0.7840909090909091\n",
      "After 95 epochs\n",
      "test accuracy: 0.8113636363636364\n",
      "After 100 epochs\n",
      "test accuracy: 0.8068181818181818\n",
      "After 105 epochs\n",
      "test accuracy: 0.8022727272727272\n",
      "After 110 epochs\n",
      "test accuracy: 0.8090909090909091\n",
      "After 115 epochs\n",
      "test accuracy: 0.8045454545454546\n",
      "After 120 epochs\n",
      "test accuracy: 0.8090909090909091\n",
      "After 125 epochs\n",
      "test accuracy: 0.7977272727272727\n",
      "After 130 epochs\n",
      "test accuracy: 0.7977272727272727\n",
      "After 135 epochs\n",
      "test accuracy: 0.8113636363636364\n",
      "After 140 epochs\n",
      "test accuracy: 0.7931818181818182\n",
      "After 145 epochs\n",
      "test accuracy: 0.8\n",
      "After 150 epochs\n",
      "test accuracy: 0.8022727272727272\n",
      "After 155 epochs\n",
      "test accuracy: 0.7909090909090909\n",
      "After 160 epochs\n",
      "test accuracy: 0.7931818181818182\n",
      "After 165 epochs\n",
      "test accuracy: 0.7886363636363637\n",
      "After 170 epochs\n",
      "test accuracy: 0.8\n",
      "After 175 epochs\n",
      "test accuracy: 0.8\n",
      "After 180 epochs\n",
      "test accuracy: 0.8090909090909091\n",
      "After 185 epochs\n",
      "test accuracy: 0.8159090909090909\n",
      "After 190 epochs\n",
      "test accuracy: 0.8022727272727272\n",
      "After 195 epochs\n",
      "test accuracy: 0.7977272727272727\n",
      "After 200 epochs\n",
      "test accuracy: 0.7977272727272727\n"
     ]
    }
   ],
   "source": [
    "test_accs = []\n",
    "\n",
    "for i in 1:200\n",
    "    \n",
    "    Knet.rmsprop!(my_model, trndata_batch;rho=0.95, gclip=5)\n",
    "    \n",
    "    if i%5 == 0\n",
    "        println(\"After $i epochs\")\n",
    "        test_acc = model_accuracy(my_model, tstdata_batch)\n",
    "        push!(test_accs, test_acc)\n",
    "        println(\"test accuracy: \", test_acc)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
