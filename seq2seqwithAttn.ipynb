{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Untitled Folder/Datasets/seq2tree_atis/test.txt\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Please enter here the paths of the training file and the test file\n",
    "training_file = \"Untitled Folder/Datasets/seq2tree_atis/train.txt\"\n",
    "test_file = \"Untitled Folder/Datasets/seq2tree_atis/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Untitled Folder/Datasets/seq2tree_geoqueries/test.txt\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Please enter here the paths of the training file and the test file\n",
    "training_file = \"Untitled Folder/Datasets/seq2tree_geoqueries/train.txt\"\n",
    "test_file = \"Untitled Folder/Datasets/seq2tree_geoqueries/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Untitled Folder/Datasets/seq2tree_jobqueries/test.txt\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file = \"Untitled Folder/Datasets/seq2tree_jobqueries/train.txt\"\n",
    "test_file = \"Untitled Folder/Datasets/seq2tree_jobqueries/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet: Knet, AutoGrad, param, param0, mat, RNN, relu, Data, adam, progress, nll, zeroone\n",
    "using Distributions\n",
    "import .Iterators: cycle, Cycle, take\n",
    "using IterTools\n",
    "import CUDA\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tok_int (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function tok_int(training_file)\n",
    "    \n",
    "    #global int2tok_input, int2tok_output\n",
    "    f = open(training_file)\n",
    "    tok2int_input = Dict{String,Int}() #keys: unique input tokens. values: id number of the token.\n",
    "    int2tok_input = Vector{String}() #indices: numbers. values: tokens corresponding to those numbers.\n",
    "    push!(int2tok_input, \"<s>\") #start token\n",
    "    push!(int2tok_input, \"</s>\") #stop token\n",
    "    tok2int_input[\"<s>\"] = 1\n",
    "    tok2int_input[\"</s>\"] = 2\n",
    "    tok2int_output = Dict{String,Int}() #keys: unique output tokens. values: id number of the token.\n",
    "    int2tok_output = Vector{String}() #keys: numbers. values: tokens corresponding to those numbers.\n",
    "    push!(int2tok_output, \"<s>\") #start token\n",
    "    push!(int2tok_output, \"</s>\") #stop token\n",
    "    tok2int_output[\"<s>\"] = 1\n",
    "    tok2int_output[\"</s>\"] = 2\n",
    "    while ! eof(f)\n",
    "        seq = readline(f)\n",
    "        seq = chomp(seq)\n",
    "        input, output = split(seq, \"\\t\")\n",
    "        tokens = split(input, \" \")\n",
    "        for token in tokens\n",
    "            if !haskey(tok2int_input, token)\n",
    "                push!(int2tok_input, token)\n",
    "                tok2int_input[token] = length(int2tok_input)\n",
    "            end            \n",
    "        end\n",
    "        tokens = split(output, \" \")\n",
    "        for token in tokens\n",
    "            if !haskey(tok2int_output, token)\n",
    "                push!(int2tok_output, token)\n",
    "                tok2int_output[token] = length(int2tok_output)\n",
    "            end           \n",
    "        end        \n",
    "    end\n",
    "    push!(int2tok_input, \"UNK\") \n",
    "    tok2int_input[\"UNK\"] = 123\n",
    "    push!(int2tok_output, \"UNK\") \n",
    "    tok2int_output[\"UNK\"] = 123\n",
    "    Vq = length(int2tok_input) #number of unique input tokens\n",
    "    Va = length(int2tok_output) #number of unique output tokens    \n",
    "    return int2tok_input, tok2int_input, int2tok_output, tok2int_output, Va, Vq\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_reader (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function data_reader(training_file, tok2int_input, tok2int_output)\n",
    "    \n",
    "    data = []\n",
    "    f = open(training_file)\n",
    "    while ! eof(f)\n",
    "        seq = readline(f)\n",
    "        seq = chomp(seq)\n",
    "        input, output = split(seq, \"\\t\")\n",
    "        tokens = split(input, \" \")\n",
    "        s = Vector{Int}() #vector that stores the token ids.\n",
    "        global n_in = 0 #just to check the number of unknown tokens\n",
    "        for token in tokens            \n",
    "            if haskey(tok2int_input, token)\n",
    "                push!(s, tok2int_input[token])\n",
    "            else\n",
    "                push!(s, tok2int_input[\"UNK\"])\n",
    "                n_in += 1\n",
    "            end \n",
    "        end        \n",
    "\n",
    "        tokens = split(output, \" \")\n",
    "        s2 = Vector{Int}() #vector that stores the token ids.\n",
    "        global n_out = 0 #just to check the number of unknown tokens\n",
    "        for token in tokens\n",
    "            if haskey(tok2int_output, token)\n",
    "                push!(s2, tok2int_output[token])\n",
    "            else\n",
    "                push!(s2, tok2int_output[\"UNK\"])\n",
    "                n_out += 1\n",
    "            end\n",
    "        end \n",
    "        push!(data, (s, s2))\n",
    "    end    \n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minibatch (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function minibatch(data,batchsize)\n",
    "    n = length(data)\n",
    "    batch_data = Any[]\n",
    "    p = 0\n",
    "    while p + batchsize <= n\n",
    "        max_seq_len = length(data[p+batchsize][1])\n",
    "        enc_seq = zeros(Int64, batchsize, max_seq_len+2) \n",
    "        enc_seq[:,1] .= 1\n",
    "        for i in 1:batchsize\n",
    "            seq = data[p+i][1]\n",
    "            seq_len = length(seq)\n",
    "            for j in 1:seq_len\n",
    "                enc_seq[i,j+1] = seq[seq_len-j+1]\n",
    "            end\n",
    "            for k in seq_len+2:max_seq_len+2 \n",
    "                enc_seq[i,k] = 2\n",
    "            end\n",
    "        end\n",
    "        max_seq_len = -1\n",
    "        for i in 1:batchsize\n",
    "            seq = data[p+i][2]\n",
    "            if length(seq) > max_seq_len \n",
    "                max_seq_len = length(seq)\n",
    "            end\n",
    "        end\n",
    "        dec_seq = zeros(Int64, batchsize, max_seq_len+2)\n",
    "        dec_seq[:,1] .= 1\n",
    "        for i in 1:batchsize\n",
    "            seq = data[p+i][2]\n",
    "            seq_len = length(seq)\n",
    "            for j in 1:seq_len\n",
    "                dec_seq[i,j + 1] = seq[j]\n",
    "            end\n",
    "            dec_seq[i,(seq_len + 2):end] .= 2\n",
    "        end\n",
    "        p += batchsize\n",
    "        push!(batch_data, (enc_seq, dec_seq))\n",
    "    end\n",
    "    return batch_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mask (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mask(a, pad)\n",
    "    a = copy(a)\n",
    "    for i in 1:size(a, 1)\n",
    "        j = size(a,2)\n",
    "        while a[i, j] == pad && j > 1\n",
    "            if a[i, j - 1] == pad\n",
    "                a[i, j] = 0\n",
    "            end\n",
    "            j -= 1\n",
    "        end\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Embed\n",
    "    w\n",
    "end\n",
    "function Embed(embedsize::Int, vocabsize::Int)\n",
    "    w = rand(Distributions.Uniform(-0.08,0.08),embedsize,vocabsize)\n",
    "    w = Knet.Param(convert(Knet.KnetArray{Float32},w))\n",
    "    return Embed(w)\n",
    "end\n",
    "(e::Embed)(x) = e.w[:,x] #x: word id\n",
    "\n",
    "struct Linear\n",
    "    w\n",
    "    b\n",
    "    f\n",
    "end\n",
    "function Linear(i::Int,o::Int,f=identity)\n",
    "    w = rand(Distributions.Uniform(-0.08,0.08),o,i)\n",
    "    w = Knet.Param(convert(Knet.KnetArray{Float32},w))\n",
    "    b = zeros(o)\n",
    "    b = Knet.Param(convert(Knet.KnetArray{Float32},b))\n",
    "    return Linear(w,b,f)\n",
    "end\n",
    "#Linear(i::Int,o::Int,f=identity) = Linear(param(o,i), param0(o), f)\n",
    "(d::Linear)(x) = d.f.(d.w * mat(x,dims=1) .+ d.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Tree\n",
    "    parent\n",
    "    num_children\n",
    "    children\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seq2seq"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct seq2seq\n",
    "    input_embed\n",
    "    output_embed\n",
    "    encoder\n",
    "    decoder\n",
    "    linear\n",
    "    linear_att\n",
    "    dropout\n",
    "    \n",
    "end\n",
    "\n",
    "function seq2seq(X::Int, H::Int, Vq::Int, Va::Int, dropout::Real)\n",
    "    a = Embed(X, Vq)\n",
    "    b = Embed(X, Va)\n",
    "    c = RNN(X, H; rnnType=:lstm, numLayers=1, dropout=dropout)\n",
    "    d = RNN(X, H; rnnType=:lstm, numLayers=1, dropout=dropout)\n",
    "    e = Linear(H,Va)\n",
    "    f = Linear(2*H, H, tanh)\n",
    "    g = dropout\n",
    "    return seq2seq(a, b, c, d, e, f, g)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_attention_vectors (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_attention_vectors(s::seq2seq, encoder_out, decoder_out, mode::Int)\n",
    "    \n",
    "    T = size(decoder_out,3)\n",
    "    h_enc = permutedims(encoder_out, [3, 1, 2]) # T,H,B\n",
    "    local attention\n",
    "   \n",
    "    h_dec = permutedims(decoder_out[:,:,1:1], [1, 3, 2]) # H,1,B\n",
    "    dot = Knet.bmm(h_enc, h_dec) # T,1,B\n",
    "    dot = permutedims(dot, [3, 1, 2]) # B,T,1\n",
    "    dot = reshape(dot, (size(dot,1), size(dot,2))) # B,T\n",
    "    attn = Knet.softmax(dot, dims=2) # B,T\n",
    "    attn = reshape(attn, (size(attn,1), size(attn,2), 1)) # B,T,1\n",
    "    attn = permutedims(attn, [2, 3, 1]) # T,1,B\n",
    "    h_enc_tr = permutedims(encoder_out, [1, 3, 2]) # H,T,B\n",
    "    context = Knet.bmm(h_enc_tr, attn) # H,1,B\n",
    "    cat_out = cat(h_dec,context; dims=1) # 2H,1,B\n",
    "    cat_out = permutedims(cat_out, [1, 3, 2]) # 2H,B,1\n",
    "    cat_out = reshape(cat_out, (size(cat_out,1), size(cat_out,2))) # 2H,B\n",
    "    h_att = s.linear_att(cat_out) # H,B    \n",
    "    attention = h_att\n",
    "    if mode == 2\n",
    "        attention = reshape(attention, (size(attention,1), size(attention,2), 1)) # H,B,1\n",
    "        return attention # H,B,1\n",
    "    elseif mode == 1\n",
    "        for i in 2:T\n",
    "            h_dec = permutedims(decoder_out[:,:,i:i], [1, 3, 2]) # H,1,B\n",
    "            dot = Knet.bmm(h_enc, h_dec) # T,1,B\n",
    "            dot = permutedims(dot, [3, 1, 2]) # B,T,1\n",
    "            dot = reshape(dot, (size(dot,1), size(dot,2))) # B,T\n",
    "            attn = Knet.softmax(dot, dims=2) # B,T\n",
    "            attn = reshape(attn, (size(attn,1), size(attn,2), 1)) # B,T,1\n",
    "            attn = permutedims(attn, [2, 3, 1]) # T,1,B\n",
    "            h_enc_tr = permutedims(encoder_out, [1, 3, 2]) # H,T,B\n",
    "            context = Knet.bmm(h_enc_tr, attn) # H,1,B\n",
    "            cat_out = cat(h_dec,context; dims=1) # 2H,1,B\n",
    "            cat_out = permutedims(cat_out, [1, 3, 2]) # 2H,B,1\n",
    "            cat_out = reshape(cat_out, (size(cat_out,1), size(cat_out,2))) # 2H,B\n",
    "            h_att = s.linear_att(cat_out) # H,B        \n",
    "            attention = cat(attention, h_att; dims=3)            \n",
    "        end\n",
    "        return attention # H,B,T\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (s::seq2seq)(x, y; average=true) \n",
    "    # x: B,Tmaxx y: B,Tmaxy\n",
    "    s.encoder.h, s.encoder.c = 0, 0\n",
    "    x_embedded = s.input_embed(x) # X,B,Tmaxx\n",
    "    y_embedded = s.output_embed(y) # X,B,Tmaxy\n",
    "    encoder_out = s.encoder(x_embedded) # H,B,Tmaxx\n",
    "    s.decoder.h, s.decoder.c = s.encoder.h, s.encoder.c    \n",
    "    decoder_out = s.decoder(y_embedded[:, :, 1:end-1]) # H,B,Tmaxy-1\n",
    "    attention = get_attention_vectors(s, encoder_out, decoder_out, 1)\n",
    "    dims = size(attention) # H,B,Tmaxx-1\n",
    "    output = s.linear(Knet.dropout(reshape(attention, dims[1], dims[2] * dims[3]), s.dropout))\n",
    "    scores = reshape(output, size(output, 1), dims[2], dims[3])\n",
    "    nll(scores, mask(y[:, 2:end], 2); dims=1, average=average)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR PREDICTION/TESTING\n",
    "function (s::seq2seq)(x; stopfactor = 4)\n",
    "    # x: B, Tmax\n",
    "    s.encoder.h, s.encoder.c = 0, 0\n",
    "    x_embedded = s.input_embed(x)\n",
    "    encoder_out = s.encoder(x_embedded)\n",
    "    s.decoder.h, s.decoder.c = s.encoder.h, s.encoder.c\n",
    "    step = fill(1, size(x)[1], 1) # B,1 --full of 1's: start tokens\n",
    "    out = fill(2, size(x)[1], 0) # B,0\n",
    "    stopping_criteria = fill(false, size(x)[1])\n",
    "    for i in 1:(stopfactor * size(x,2))\n",
    "        if sum(stopping_criteria) == size(x)[1]\n",
    "            break\n",
    "        end\n",
    "        stepembed = s.output_embed(step) # X,B,1\n",
    "        decoder_out = s.decoder(stepembed) # H,B,1\n",
    "        attention = get_attention_vectors(s, encoder_out, decoder_out, 2) # H,B,1\n",
    "        dims = size(attention) # H,B,1\n",
    "        output = s.linear(reshape(attention, dims[1], dims[2] * dims[3])) # H,B\n",
    "        step = transpose([i[1] for i in argmax(output; dims=1)]) # B,1\n",
    "        out = hcat(out, step) # B,?\n",
    "        for e in findall(x -> x == 2, step)\n",
    "            stopping_criteria[e[1]] = true\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function model_accuracy(model, data)\n",
    "    total = 0\n",
    "    no_sequences = 0\n",
    "    for (x, y) in data\n",
    "        y_pred = model(x)\n",
    "        for i in 1:size(x, 1)\n",
    "            no_sequences += 1            \n",
    "            y_clipped = []\n",
    "            y_pred_clipped = []\n",
    "            for j in 1:size(y,2)                \n",
    "                if y[i,j] == 2                   \n",
    "                    append!(y_clipped, y[i,2:j])\n",
    "                    break\n",
    "                end\n",
    "            end            \n",
    "            for j in 1:size(y_pred,2)\n",
    "                if y_pred[i,j] == 2 \n",
    "                    append!(y_pred_clipped, y_pred[i,1:j])\n",
    "                    break\n",
    "                end\n",
    "            end\n",
    "            if length(y_clipped) == length(y_pred_clipped)\n",
    "                if sum(y_pred_clipped .== y_clipped) == size(y_clipped,1)                   \n",
    "                    total += 1                    \n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return total / no_sequences    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lrdecay! (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrdecay!(s::seq2seq, decay::Real) =\n",
    "    for p in Knet.params(s); p.opt.lr = p.opt.lr*decay; end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Any,1}:\n",
       " ([1 29 … 2 2; 1 14 … 2 2; … ; 1 20 … 34 2; 1 18 … 34 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 16 … 2 2; 1 20 … 2 2; … ; 1 16 … 25 2; 1 20 … 25 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 62 … 2 2; 1 14 … 2 2; … ; 1 18 … 5 2; 1 12 … 79 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 18 … 2 2; 1 52 … 2 2; … ; 1 16 … 59 2; 1 26 … 5 2], [1 19 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 18 … 2 2; 1 99 … 2 2; … ; 1 14 … 9 2; 1 24 … 5 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 22 … 6 2; 1 3 … 2 2])\n",
       " ([1 14 … 2 2; 1 45 … 2 2; … ; 1 86 … 5 2; 1 14 … 5 2], [1 3 … 2 2; 1 3 … 2 2; … ; 1 3 … 2 2; 1 3 … 2 2])\n",
       " ([1 18 … 2 2; 1 31 … 2 2; … ; 1 26 … 2 2; 1 18 … 9 2], [1 3 … 2 2; 1 8 … 2 2; … ; 1 3 … 2 2; 1 3 … 6 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2tok_input, tok2int_input, int2tok_output, tok2int_output, Va, Vq = tok_int(training_file)\n",
    "trndata = data_reader(training_file, tok2int_input, tok2int_output)\n",
    "tstdata = data_reader(test_file, tok2int_input, tok2int_output)\n",
    "X = 200\n",
    "H = 200 \n",
    "trndata_batch = minibatch(trndata, 20)\n",
    "tstdata_batch = minibatch(tstdata, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seq2seq(Embed(P(Knet.KnetArrays.KnetArray{Float32,2}(200,173))), Embed(P(Knet.KnetArrays.KnetArray{Float32,2}(200,50))), LSTM(input=200,hidden=200,dropout=0.4), LSTM(input=200,hidden=200,dropout=0.4), Linear(P(Knet.KnetArrays.KnetArray{Float32,2}(50,200)), P(Knet.KnetArrays.KnetArray{Float32,1}(50)), identity), Linear(P(Knet.KnetArrays.KnetArray{Float32,2}(200,400)), P(Knet.KnetArrays.KnetArray{Float32,1}(200)), tanh), 0.4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = seq2seq(X,H,Vq,Va,0.4) # dropout=0.4 for GEO and JOBS datasets, dropout = 0.3 for ATIS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 epochs\n",
      "test accuracy: 0.0\n",
      "After 10 epochs\n",
      "test accuracy: 0.1\n",
      "After 15 epochs\n",
      "test accuracy: 0.0\n",
      "After 20 epochs\n",
      "test accuracy: 0.12857142857142856\n",
      "After 25 epochs\n",
      "test accuracy: 0.0\n",
      "After 30 epochs\n",
      "test accuracy: 0.40714285714285714\n",
      "After 35 epochs\n",
      "test accuracy: 0.6285714285714286\n",
      "After 40 epochs\n",
      "test accuracy: 0.6857142857142857\n",
      "After 45 epochs\n",
      "test accuracy: 0.6857142857142857\n",
      "After 50 epochs\n",
      "test accuracy: 0.7571428571428571\n",
      "After 55 epochs\n",
      "test accuracy: 0.7714285714285715\n",
      "After 60 epochs\n",
      "test accuracy: 0.7571428571428571\n",
      "After 65 epochs\n",
      "test accuracy: 0.7785714285714286\n",
      "After 70 epochs\n",
      "test accuracy: 0.7785714285714286\n",
      "After 75 epochs\n",
      "test accuracy: 0.6857142857142857\n",
      "After 80 epochs\n",
      "test accuracy: 0.7928571428571428\n",
      "After 85 epochs\n",
      "test accuracy: 0.7714285714285715\n",
      "After 90 epochs\n",
      "test accuracy: 0.7928571428571428\n",
      "After 95 epochs\n",
      "test accuracy: 0.8071428571428572\n",
      "After 100 epochs\n",
      "test accuracy: 0.7857142857142857\n",
      "After 105 epochs\n",
      "test accuracy: 0.7785714285714286\n",
      "After 110 epochs\n",
      "test accuracy: 0.7928571428571428\n",
      "After 115 epochs\n",
      "test accuracy: 0.7571428571428571\n",
      "After 120 epochs\n",
      "test accuracy: 0.7857142857142857\n",
      "After 125 epochs\n",
      "test accuracy: 0.7857142857142857\n",
      "After 130 epochs\n",
      "test accuracy: 0.7857142857142857\n",
      "After 135 epochs\n",
      "test accuracy: 0.7857142857142857\n",
      "After 140 epochs\n",
      "test accuracy: 0.7928571428571428\n",
      "After 145 epochs\n",
      "test accuracy: 0.7857142857142857\n",
      "After 150 epochs\n",
      "test accuracy: 0.7785714285714286\n",
      "After 155 epochs\n",
      "test accuracy: 0.7857142857142857\n",
      "After 160 epochs\n",
      "test accuracy: 0.7857142857142857\n",
      "After 165 epochs\n",
      "test accuracy: 0.7785714285714286\n",
      "After 170 epochs\n",
      "test accuracy: 0.7928571428571428\n",
      "After 175 epochs\n",
      "test accuracy: 0.7928571428571428\n",
      "After 180 epochs\n",
      "test accuracy: 0.7928571428571428\n",
      "After 185 epochs\n",
      "test accuracy: 0.7928571428571428\n",
      "After 190 epochs\n",
      "test accuracy: 0.7928571428571428\n",
      "After 195 epochs\n",
      "test accuracy: 0.7928571428571428\n",
      "After 200 epochs\n",
      "test accuracy: 0.7928571428571428\n"
     ]
    }
   ],
   "source": [
    "for i in 1:200\n",
    "    Knet.rmsprop!(my_model, trndata_batch;rho=0.95,gclip=5)\n",
    "    if i%5 == 0\n",
    "        println(\"After $i epochs\")\n",
    "        #println(\"train accuracy: \", model_accuracy(my_model, trndata_batch))\n",
    "        println(\"test accuracy: \", model_accuracy(my_model, tstdata_batch))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
